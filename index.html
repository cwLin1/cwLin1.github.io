<!DOCTYPE HTML PUBLIC "-//W3C//DTD HTML 4.01 Transitional//EN">
<html>

<head>
  <meta name="generator" content="HTML Tidy for Linux/x86 (vers 11 February 2007), see www.w3.org">
  <style type="text/css">
  /* Design Credits: Jon Barron and Abhishek Kar and Saurabh Gupta*/
  a {
  color: #1772d0;
  text-decoration:none;
  }
  a:focus, a:hover {
  color: #f09228;
  text-decoration:none;
  }
  body,td,th {
    font-family: 'Titillium Web', Verdana, Helvetica, sans-serif;
    font-size: 16px;
    font-weight: 400
  }
  heading {
    font-family: 'Titillium Web', Verdana, Helvetica, sans-serif;
    font-size: 19px;
    font-weight: 1000
  }
  strong {
    font-family: 'Titillium Web', Verdana, Helvetica, sans-serif;
    font-size: 16px;
    font-weight: 800
  }
  strongred {
    font-family: 'Titillium Web', Verdana, Helvetica, sans-serif;
    color: 'red' ;
    font-size: 16px
  }
  sectionheading {
    font-family: 'Titillium Web', Verdana, Helvetica, sans-serif;
    font-size: 22px;
    font-weight: 600
  }
  pageheading {
    font-family: 'Titillium Web', Verdana, Helvetica, sans-serif;
    font-size: 38px;
    font-weight: 400
  }
  </style>
  <link rel="icon" type="image/png" href="images/icon.png">
  <script type="text/javascript" src="js/hidebib.js"></script>
  <title>Cheng-Wei Lin</title>
  <meta name="Cheng-Wei Lin's Homepage" http-equiv="Content-Type" content="Cheng-Wei Lin's Homepage">
  <link href='https://fonts.googleapis.com/css?family=Titillium+Web:400,600,400italic,600italic,300,300italic' rel='stylesheet' type='text/css'>
  <!-- Start : Google Analytics Code -->
  <!-- <script>
    (function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
    (i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
    m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
    })(window,document,'script','//www.google-analytics.com/analytics.js','ga');
    ga('create', 'UA-64069893-1', 'auto');
    ga('send', 'pageview');
  </script> -->
  <!-- End : Google Analytics Code -->
  <!-- Scramble Script by Jeff Donahue -->
  <script src="js/scramble.js"></script>
</head>

<body>
<table width="840" border="0" align="center" border="0" cellspacing="0" cellpadding="20">
  <tr><td>

<table width="100%" align="center" border="0" cellspacing="0" cellpadding="20">
  <p align="center">
    <!-- <font size="7">Yen-Chi Cheng</font><br> -->
    <pageheading>Cheng-Wei Lin</pageheading><br>
    <!-- <b>email</b>: charlescheng0117_at_gmail_dot_com -->
    <b>E-mail</b>: lindavid1688@gmail.com &nbsp &nbsp <b>Phone</b>: +886 970-911-688
    <font id="email" style="display:inline;">
      <noscript><i>Please enable Javascript to view</i></noscript>
    </font>
    <!-- <script>
    emailScramble = new scrambledString(document.getElementById('email'),
        'emailScramble', '1cm0asg17eccmilnrlah.oge@h',
        [14, 8, 19, 13, 20, 7, 12, 15, 16, 6, 1, 24, 26, 21, 5, 11, 4, 22, 3, 9, 23, 25, 18, 10, 17, 2]);
        // 'emailScramble', 'charlescheng0117@gmail.com',
        // [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26]);
    </script> -->
  </p>

  <tr>
    <td width="32%" valign="top"><a href="images/cwlin.jpg"><img src="images/cwlin.jpg" width="100%" style="border-radius:15px"></a>
        <p align=center>
            | <a href="Software_Engineer_Resume-250428.pdf">Resume</a> |
            <!-- <a href="https://scholar.google.cl/citations?hl=en&pli=1&user=wvuEiWgAAAAJ">Google Scholar</a> |<br/>| -->
            <a href="https://github.com/cwlin1">Github</a> |
            <a href="https://www.linkedin.com/in/chengwei-lin/">LinkedIn</a> |
        </p>
    </td>

    <td width="68%" valign="top" align="justify">
        <p>
        I recently graduated from the Master's program in the Department of Computer Science at National Taiwan University in June 2023. 
        Throughout my academic journey, I have specialized in computer vision algorithms and machine learning research, 
        conducting research at the Digital Camera and Computer Vision Laboratory. 
        <br>
        <br>
        Previously, I interned at <a href= "https://medicapture.com/">MediCapture</a>. 
        I am actively contributing to the development of image processing algorithms for orthopedic surgeries and ophthalmic surgeries, 
        gaining valuable industry experience.
        <br>
        <br>
        With my foundation and experience in computer vision and deep learning, 
        I am actively seeking for an opportunity where I can use my skills to take on the position of a 
        <b> software engineer</b>.

        <br>
        </p>

        </td>
  </tr>
</table>


<!-- =================== Experience =================== -->
<table width="100%" align="center" style="margin-left:10px" cellspacing="0" cellpadding="0" border="0">
    <tr>
        <!-- <th width="16.6%" valign="top" align="center"> -->
        <!-- <img src="images/uiuc.png" alt="sym" width="60%"></a>
        <p style="line-height:1.3; font-size:12pt">UIUC<br>MCS<br>Aug. 21 - Dec. 22</p> -->
        <!-- </th> -->

        <!-- <th width="16.6%" valign="top" align="center"> -->
        <!-- <img src="images/nvidia.png" alt="sym" width="60%"></a>
        <p style="line-height:1.3; font-size:12pt">NVIDIA<br>Software Intern<br>May. 22 - Aug. 22</p> -->
        <!-- </th> -->

        <!-- <th width="16.6%" valign="top" align="center"> -->
        <!-- <p style="line-height:1.5;"><br></p> -->
        <!-- <img src="images/intouch.png" alt="sym" width="60%"></a>
        <p style="line-height:1.3; font-size:12pt">Intouch Games<br>C++ Backend Engineer<br>Sep. 20 - May. 21</p> -->
        <!-- </th> -->

        <th width="16.6%" valign="top" align="center">
        <img src="images/medicapture_inc__logo.jpg" alt="sym" width="60%"></a>
        <p style="line-height:1.3; font-size:12pt">MediCapture<br>Software Engineer Intern</p>
        </th>

        <!-- <th width="16.6%" valign="top" align="center"></th> -->

        <th width="16.6%" valign="top" align="center">
        <img src="images/ntu.png" alt="sym" width="60%"></a>
        <p style="line-height:1.3; font-size:12pt">National Taiwan University<br>M.S. in CSIE</p>
        </th>

        <!-- <th width="16.6%" valign="top" align="center"></th> -->

        <th width="16.6%" valign="top" align="center">
        <img src="images/yzu.png" alt="sym" width="60%"></a>
        <p style="line-height:1.3; font-size:12pt">Yuan-Ze University<br>B.S. in EE</p>
        </th>

    </tr>
</table>
<br>
<table width="100%" align="center" border="0" cellspacing="0" cellpadding="8">
  <tr><td>
    <sectionheading>&nbsp;&nbsp;News</sectionheading>
    <ul>
      <li> [07/2023] One paper accepted at <b>CVGIP'23</b>.</li>
      <li> [01/2023] Start my software engineer internship at <b>MediCapture</b>.</li>
      <li> [04/2022] One paper accepted at <b>ITAOI'22</b>. (Best Paper Award)</li>
      <li> [09/2021] Start my graduate study at <b>NTU</b> advised by <a href="https://www.csie.ntu.edu.tw/~fuh/">Prof. Chiou-Shann Fuh</a>.</li>
      <li> [02/2019] Start working as a research student at YZU advised by <a href="https://eea.ee.yzu.edu.tw/teacher_detail/dychen">Prof. Duan-Yu Chen</a>.</li>
      <!-- <li> [05/2022] Start my internship at <b>NVIDIA</b> TensorRT team!</li>
      <li> [08/2021] Start my graduate study at <b>UIUC MCS</b>.</li>
      <li> [09/2020] Start my job at <b>Intouch Games Ltd.</b>.</li>
      <li> [03/2020] Start my internship at <b>Logitech</b> MBG PQA team.</li>
      <li> [01/2020] One paper accepted at <b>ISCAS'20</b>.</li>
      <li> [04/2019] Start working as a research student at NCTU advised by <a href="https://sites.google.com/g2.nctu.edu.tw/wpeng">Prof. Wen-Hsiao Peng</a>.</li>
      <li> [09/2017] Start participating in the UI/UX department at<b> NCTU+</b>.</li> -->
    </ul>
  </td></tr>
</table>

<table width="100%" align="center" border="0" cellspacing="0" cellpadding="10">
  <tr><td><sectionheading>&nbsp;&nbsp;Publications</sectionheading></td></tr>
</table>
<table width="100%" align="center" border="0" cellspacing="0" cellpadding="15">

    <tr>
        <td width="33%" valign="top" align="center">
            <a href="#">
            <!-- <img src="images/vis.png" alt="sym" width="100%" height="14%" style="border-radius:15px"></a> -->
            <img src="images/cvgip23.png" alt="sym" width="300" height="200" style="border-radius:15px">
        </td>

        <td width="67%" valign="top">
            <p>
                <a href="#" id="CVGIP23"></a>
                <heading>LinAlign: X-Ray Image Alignment before and after Total Hip Arthroplasty.</heading></a>
                <br>
                <u><b>Cheng-Wei Lin</b></u>, Alexander Yurusov, and Chiou-Shann Fuh
                <br>
                CVGIP 2023
                <br>
            </p>
    
            <div class="paper" id="CVGIP23">
            <!-- <a href="https://zswang666.github.io/P2PVG-Project-Page/">webpage</a> | -->
            | <a href="javascript:toggleblock('CVGIP23_abs')">abstract</a> |
            <a href="https://drive.google.com/file/d/1ZWrYl7wmE4HRASM43riI6Go7keboSRpB/view?usp=sharing">video</a> |
            <a href="doc/CVGIP2023-CWLin.pdf">pdf</a> |
            <!-- <a href="https://arxiv.org/abs/1904.03086">arXiv</a> -->
            <!-- <a href="https://github.com/yccyenchicheng/p2pvg">code</a> -->
    
            <p align="justify">
                <i id='CVGIP23_abs'>
                  In this paper, we propose LinAlign: a computer vision algorithm for aligning X-ray images before and after surgery, 
                  providing a system for surgeons to compare images before and after surgery more efficiently and replace manually aligning procedure. 
                  LinAlign allows only align specific area when aligning images, and solve the problem that linear transformation cannot be performed 
                  on non-rigid objects. Therefore, it is suitable for comparing the position of bones during the hip replacement surgery, 
                  allowing orthopedic surgeons to make sure that implants have been installed correctly.

                  In our experiment, we took the X-ray images of the pelvis as our experimental data: each set of images contains the X-ray 
                  photographs of the same patient taken at different times. We experiment with different methods. By comparing similar features 
                  between images and calculating the displacement of these feature points, the images can be aligned.

                  We evaluate the performance of the algorithm by the error of pre-defined landmarks after alignment. These landmarks are 
                  anatomically important features of the skeletal system. The goal of our experiment is to minimize the distance of landmarks 
                  between image pair. We take the mean square error of these landmark distances as the performance metric to our algorithm.
                </i>
            </p>
    
            <!-- <pre xml:space="preserve">
            @article{chao18radiotherapy,
                title     = {Radiotherapy Target Contouring with Convolutional Gated Graph Neural
                             Network},
                author    = {Chao, Chun-Hung and Cheng, Yen-Chi and Cheng, Hsien-Tzu and Huang, Chi-Wen and
                             Ho, Tsung-Ying and Tseng, Chen-Kan
                            Lu, Le and Sun, Min},
                journal   = {arXiv preprint arXiv:1904.02912},
                year      = {2019},
                }
            </pre> -->

            </div>
        </td>
    </tr>

    <tr>
      <td width="33%" valign="top" align="center">
          <a href="#">
          <!-- <img src="images/vis.png" alt="sym" width="100%" height="14%" style="border-radius:15px"></a> -->
          <img src="images/itaoi22.png" alt="sym" width="300" height="200" style="border-radius:15px">
      </td>

      <td width="67%" valign="top">
          <p>
              <a href="#" id="ITAOI22"></a>
              <heading>Detection of Operators’ Inspection Quality in Car Factory.</heading></a>
              <br>
              <u><b>Cheng-Wei Lin</b></u> and Chiou-Shann Fuh
              <br>
              ITAOI 2022 <b>(Best Paper Award)</b>
              <br>
          </p>
  
          <div class="paper" id="ITAOI22">
          <!-- <a href="https://zswang666.github.io/P2PVG-Project-Page/">webpage</a> | -->
          | <a href="javascript:toggleblock('ITAOI22_abs')">abstract</a> |
          <a href="https://drive.google.com/file/d/1Cqkyy6j8F1VXeWVPPt2HZd9jUQlVXGgo/view?usp=sharing">video</a> |
          <a href="doc/Detection of Operators’ Inspection Quality in Car Factory.pdf">pdf</a> |
          <!-- <a href="https://arxiv.org/abs/1904.03086">arXiv</a> -->
          <!-- <a href="https://github.com/yccyenchicheng/p2pvg">code</a> -->
  
          <p align="justify">
              <i id='ITAOI22_abs'>
                In this paper, we propose a computer vision, image processing, and automatic optical inspection solution to detect 
                operator motion and quality assurance in the car factory. Our goal is to create a system to check the operators have 
                inspected all inspection points on each car.
                We set up two cameras on both sides of production line to detect car and operator locations. Inspection points defined 
                by car factory are mapped onto the car. Initially, these points are uninspected and marked by gray. When the operator’s 
                glove touches the inspection point, the inspected points are changed into green as inspected. After the car passes 
                through the inspected area, we save inspection result, and inspect next car.
                Deep learning and image processing algorithm are used in our system. We first use object detection algorithm to detect 
                the wheel and map inspection points onto the car by relative position to wheels. Then, we find the operator by pose 
                estimation algorithm, Blazepose. When the glove touches inspection point, then that point will be recorded as inspected 
                (changed from gray to green).

              </i>
          </p>
  
          <!-- <pre xml:space="preserve">
          @article{chao18radiotherapy,
              title     = {Radiotherapy Target Contouring with Convolutional Gated Graph Neural
                           Network},
              author    = {Chao, Chun-Hung and Cheng, Yen-Chi and Cheng, Hsien-Tzu and Huang, Chi-Wen and
                           Ho, Tsung-Ying and Tseng, Chen-Kan
                          Lu, Le and Sun, Min},
              journal   = {arXiv preprint arXiv:1904.02912},
              year      = {2019},
              }
          </pre> -->

          </div>
      </td>
  </tr>

<br>
<br>

<table width="100%" align="center" border="0" cellspacing="0" cellpadding="10">
        <tr><td><sectionheading>&nbsp;&nbsp;Projects</sectionheading></td></tr>
</table>
<table width="100%" align="center" border="0" cellspacing="0" cellpadding="15">


    <tr>
        <td width="50%" valign="top" align="center">
            <!-- <a href="https://drive.google.com/file/d/1E1JoDSI_be8pjUFMkHGJu5WJtz53hYRT/view?usp=sharing"> -->
            <img src="images/tiolida.png" alt="sym" width="300" height="200" style="border-radius:15px">
        </td>

        <td width="50%" valign="top">
            <p>
                <!-- <a href="https://drive.google.com/file/d/1E1JoDSI_be8pjUFMkHGJu5WJtz53hYRT/view?usp=sharing" id="TIOLIDA"> -->
                <heading>Toric IOL Implant Digital Alignment (TIOLIDA)</heading>
                <br>
                This project is proposed by <a href="https://www.bausch.com/">Bausch + Lomb</a> for cataract surgery requirement.
                We augment graphic overlay over the live video of an eye from the surgical microscope to assist the surgeon with 
                the alignment of the toric intraocular lens implant.
                Accurate alignment of lens implant is a prerequisite for achieving optimal visual outcome. 
                With the assist of our system, surgeons can be more precise during the operation, and reduce the risk of astigmatism.
                <!-- <a href="https://ieeexplore.ieee.org/document/9399785">Y. Zhai et al., JBHI 2021</a>. -->
                <br>
                <!-- | <a href="https://drive.google.com/file/d/1E1JoDSI_be8pjUFMkHGJu5WJtz53hYRT/view?usp=sharing">pdf</a> | -->
            </p>
    
        </td>
    </tr>

    <tr>
      <td width="50%" valign="top" align="center">
          <!-- <a href="https://drive.google.com/file/d/1GI4efJ5aIzY_ARBu7iqCgqtMFJE5kOug/view?usp=sharing"> -->
          <img src="images/linalign.png" alt="sym" width="300" height="150" style="border-radius:15px">
      </td>

      <td width="50%" valign="top">
          <p>
              <!-- <a href="https://drive.google.com/file/d/1GI4efJ5aIzY_ARBu7iqCgqtMFJE5kOug/view?usp=sharing" id="LINALIGN"> -->
              <heading>Automatic Image Alignment for Total Hip Arthroplasty</heading>
              <br>
                Proposed an automatic image alignment algorithm for images taken before and during Total Hip Arthroplasty. 
                Deploy our algorithm as desktop application and web application to make our system easy to use at clinic.
              <br>
              | <a href="https://drive.google.com/file/d/1GI4efJ5aIzY_ARBu7iqCgqtMFJE5kOug/view?usp=sharing">video</a> |
          </p>
  
      </td>
    </tr>

    <tr>
      <td width="50%" valign="top" align="center">
          <!-- <a href="https://drive.google.com/file/d/1GI4efJ5aIzY_ARBu7iqCgqtMFJE5kOug/view?usp=sharing"> -->
          <img src="images/UAV.png" alt="sym" width="300" height="200" style="border-radius:15px">
      </td>

      <td width="50%" valign="top">
          <p>
              <!-- <a href="https://drive.google.com/file/d/1GI4efJ5aIzY_ARBu7iqCgqtMFJE5kOug/view?usp=sharing" id="LINALIGN"> -->
              <heading>Object Detection on UAV images</heading>
              <br>
                Detect and recognize the tiny objects on aerial images in different scenarios. 
                We took YOLOv7 as our model, and imporoved the performance with additional detection head and attentional modules.
              <br>
              | <a href="https://github.com/Anderson-Wu/YOLOv7_for_tiny_object_detection">code</a> |
              <a href="doc/UAV.pdf">pdf</a> |
          </p>
  
      </td>
    </tr>

    <tr>
      <td width="50%" valign="top" align="center">
          <!-- <a href="https://drive.google.com/file/d/1GI4efJ5aIzY_ARBu7iqCgqtMFJE5kOug/view?usp=sharing"> -->
          <img src="images/3dcv.JPG" alt="sym" width="300" height="150" style="border-radius:15px">
      </td>

      <td width="50%" valign="top">
          <p>
              <!-- <a href="https://drive.google.com/file/d/1GI4efJ5aIzY_ARBu7iqCgqtMFJE5kOug/view?usp=sharing" id="LINALIGN"> -->
              <heading>Speed Estimation using Optical Flow</heading>
              <br>
                With dashcam recoreded videos, we proposed a method to estimate the vehicle speed using optical flow model and 
                CNN based speed estimater. For a video or live stream, we first compute its optical flow for each consecutive frames, 
                and predict the speed with a deep neural network.
              <br>
              | <a href="https://drive.google.com/file/d/1i58eQbyFn4ytq-U1dQqgZkm655iqh5bt/view"> video </a> |
              <a href="https://github.com/Brian90709/3d_final_project">code</a> |
              <a href="doc/Speed Estimation using Optical Flow.pdf">pdf</a> |
          </p>
  
      </td>
    </tr>


    <tr>
      <td width="50%" valign="top" align="center">
          <!-- <a href="https://drive.google.com/file/d/1GI4efJ5aIzY_ARBu7iqCgqtMFJE5kOug/view?usp=sharing"> -->
          <img src="images/spml.png" alt="sym" width="300" height="100" style="border-radius:15px">
      </td>

      <td width="50%" valign="top">
          <p>
              <!-- <a href="https://drive.google.com/file/d/1GI4efJ5aIzY_ARBu7iqCgqtMFJE5kOug/view?usp=sharing" id="LINALIGN"> -->
              <heading>Training with Noisy Labeled Dataset</heading>
              <br>
                In this project, we survey some common
                techniques of noisy training and present a framework that combines multi-round
                training and label refurbishment. We showed that our method outperform the
                normal training process. In the two-class classification problem, even when 40%
                of the data is mislabeled, our model still gets an accuracy of 85%.
              <br>
              |
              <a href="https://github.com/cwLin1/SPML-Final">code</a> |
              <a href="doc/SPML_Final_Report.pdf">pdf</a> |
          </p>
  
      </td>
    </tr>


    <tr>
      <td width="50%" valign="top" align="center">
          <!-- <a href="https://drive.google.com/file/d/1GI4efJ5aIzY_ARBu7iqCgqtMFJE5kOug/view?usp=sharing"> -->
          <img src="images/odrash.jpg" alt="sym" width="200" height="200" style="border-radius:15px"></a>
      </td>

      <td width="50%" valign="top">
          <p>
              <!-- <a href="https://drive.google.com/file/d/1GI4efJ5aIzY_ARBu7iqCgqtMFJE5kOug/view?usp=sharing" id="LINALIGN"> -->
              <heading>Object Detection and Recognition with Its Application to Smart Homecare</heading></a>
              <br>
              This is a Collaboration Project with Industrial Technology Research Institute (ITRI) and Taipei Veterans General Hospital (TVGH). 
              We designed the real-time recognition system (OD-RASH) to obtain blood pressure values and emergency notifications. 
              To evaluate the accuracy of numerical identification, we simulate all the scenarios that will be encountered when shooting 
              blood pressure monitor images for testing, and achieve to 99.8% accuracy.
              <br>
              | <a href="https://drive.google.com/file/d/1RywmDKubgL7i9ze9MR1_XIBBmHRljXdA/view?usp=share_link"> video </a> |
              <a href="https://github.com/marcovwu/Blood_Pressure_APP">code</a> |
              <a href="https://drive.google.com/file/d/1NEnkpIZw-vfwN9As-DUmmsThDctedPNR/view">pdf</a> |
              
          </p>
  
      </td>
    </tr>
    
    <!-- <tr>
      <td width="50%" valign="top" align="center">
          <a href="https://drive.google.com/file/d/13GEmPNO3k1miItbN21nQU4KYWB1Nc_kj/view?usp=sharing">
          <img src="images/ml.png" alt="sym" width="300" height="200" style="border-radius:15px"></a>
      </td>

      <td width="50%" valign="top">
          <p>
              <a href="https://drive.google.com/file/d/13GEmPNO3k1miItbN21nQU4KYWB1Nc_kj/view?usp=sharing" id="ML">
              <img src="images/new.png" alt="[NEW]" width="6%" style="border-style: none">
              <heading>League of Legends -- The Consistency between Emotion Management and Rank</heading></a>
              <br>
              Collected data and employed 4 machine learning models to explore relationships between players' 
              emotion management and their performances in League of Legends
              <br>
               | <a href="https://drive.google.com/file/d/13GEmPNO3k1miItbN21nQU4KYWB1Nc_kj/view?usp=sharing">video</a> |
          </p>
  
      </td>
  </tr> -->

  <!-- <tr>
    <td width="50%" valign="top" align="center">
        <a href="https://youtu.be/Cr4eDMfOO_4">
        <img src="images/uav.png" alt="sym" width="300" height="200" style="border-radius:15px"></a>
    </td>

    <td width="50%" valign="top">
        <p>
            <a href="https://youtu.be/Cr4eDMfOO_4" id="UAV">
            <img src="images/new.png" alt="[NEW]" width="6%" style="border-style: none">
            <heading>UAV Autopilot-- Face Detection and Obstacle Avoidance</heading></a>
            <br>
            Designed a system for drones that can 
            utilize computer vision to perform autonomous navigation and landing from one point to another 
            while avoiding human faces on a track.
            <br>
            | <a href="https://youtu.be/Cr4eDMfOO_4">demo video (only includes marker detection)</a> |
        </p>

    </td>
</tr> -->

<!-- <table width="100%" align="center" border="0" cellpadding="10">
  <tr>
    <td>
      <sectionheading>&nbsp;&nbsp;Honor and Awards</sectionheading>
        <ul>
          <li>Tau Beta Pi Engineering Honor Society Outstanding Graduate Awards, UIUC</li>
          <li>SS Radhakrishnan Scholarship, UIUC</li>
          <li>Tau Beta Pi Engineering Honor Society Member, UIUC</li>
          <li>IEEE Eta Kappa Nu Honor Society Member, Taiwan</li>
          <li>1st Place, Taiwan Intelligent Transportation Creative Idea Competition (ITCIC)</li>
          <li>Yang Li Lau Tai Scholarship</li>
          <li>Teacher Association Scholarship, New Taipei City Educational Association</li>
          <li>Outstanding Academic Achievement Award, NCTU</li>
          <li>Rotary Club of Yung Ho Fellowship</li>
          <li>Outstanding Academic Achievement Award in Digital Circuit Design, NCTU</li>
        </ul>
    </td>
  </tr>
</table> -->

<table width="100%" align="center" border="0" cellspacing="0" cellpadding="20">
    <tr><td><br><p align="right"><font size="2">
    Template: <a href="https://daisy91530.github.io/">this</a>
    </font></p></td></tr>
    
</table>
  </td> </tr>
</table>

<script xml:space="preserve" language="JavaScript">
hideallbibs();
</script>

<script xml:space="preserve" language="JavaScript">
hideblock('CVGIP23_abs');
</script>
<script xml:space="preserve" language="JavaScript">
  hideblock('ITAOI22_abs');
  </script>
</script>
</body>

</html>
